"""Defines an explainer for mG models.

This module defines the means to generate the sub-graph of all nodes that influenced the final label of some query node.

The module contains the following functions:
- ``explanation_nodes(explanation)``
- ``make_graph(explanation, hierarchy, old_graph, labels)``

The module contains the following classes:
- ``MGExplainer``
"""
from __future__ import annotations

import re
import typing
from copy import deepcopy
from typing import Callable, Literal

from lark import Tree, Token
from lark.exceptions import VisitError
from lark.visitors import Interpreter
import tensorflow as tf
from scipy.sparse import coo_matrix
from spektral.data import Graph
from multiprocessing.pool import ThreadPool

from libmg.compiler.functions import PsiLocal, Phi, Sigma
from libmg.compiler.compiler import MGCompiler, MGModel, Context
from libmg.language.grammar import mg_parser
from libmg.compiler.layers import unpack_inputs
from libmg.visualizer.visualizer import print_graph


def explanation_nodes(explanation: tf.Tensor[bool]) -> list[int]:
    """Returns the nodes that are part of the explanation.

    Args:
        explanation: The boolean tensor of shape ``(n_nodes,)`` that marks with ``True`` the nodes that are part of the explanation
            and ``False`` those that do not.
    """
    return typing.cast(list[int], tf.squeeze(tf.where(explanation), axis=-1).numpy().tolist())


def make_graph(explanation: tf.Tensor[bool], hierarchy: tf.Tensor[float], old_graph: tuple[tf.Tensor, ...], actual_outputs: tf.Tensor) -> Graph:
    """Returns the explanation sub-graph.

    Args:
        explanation: The boolean tensor of shape ``(n_nodes,)`` that marks with ``True`` the nodes that are part of the explanation
            and ``False`` those that do not.
        hierarchy: The hierarchy tensor of shape ``(n_nodes,)`` that assigns a numerical value to every node in the explanation. The query node is assigned 0,
            and each >0 number indicates the number of hops of distance to the query node.
        old_graph: The input graph of the explained model.
        actual_outputs: The outputs generated by the explained model.
    """
    node_feats, adj, edge_feats, _ = unpack_inputs(old_graph)

    new_node_feats = tf.boolean_mask(node_feats, explanation).numpy()
    new_actual_outputs = [tf.boolean_mask(output, explanation).numpy() for output in actual_outputs]

    nodes = set(explanation_nodes(explanation))
    edges = adj.indices.numpy().tolist()
    with ThreadPool() as pool:
        edge_mask = pool.map(lambda edge: edge[0] in nodes and edge[1] in nodes, edges)
    new_adj = tf.sparse.retain(adj, edge_mask)
    new_adj = coo_matrix((new_adj.values.numpy(), (new_adj.indices.numpy()[:, 0], new_adj.indices.numpy()[:, 1])),
                         shape=adj.shape)

    new_edge_feats = tf.boolean_mask(edge_feats, edge_mask).numpy() if edge_feats is not None else None

    hierarchy = tf.cast(hierarchy, dtype=tf.int64).numpy().tolist()

    new_graph = Graph(x=new_node_feats, a=new_adj, e=new_edge_feats, y=new_actual_outputs, hierarchy=hierarchy)

    return new_graph


class MGExplainer(Interpreter):
    """Generates an explanation for a mG model output.

    Generates the sub-graph of nodes that are responsible for the label of a given node.

    Attributes:
        model: The model to explain.
        query_node: The node of the input graph for which the sub-graph of relevant nodes will be generated.
        context: The context in which the current expression is being evaluated.
        compiler: The compiler for the explainer.
    """
    INF = 1e38
    localize_node = PsiLocal.make_parametrized('localize_node', lambda y: lambda x: tf.one_hot(indices=[int(y)],
                                                                                               depth=tf.shape(x)[0],
                                                                                               axis=0,
                                                                                               on_value=0,
                                                                                               off_value=MGExplainer.INF, dtype=tf.float32))
    proj1 = Phi(lambda i, e, j: i)
    or_agg = Sigma(lambda m, i, n, x: tf.minimum(tf.math.unsorted_segment_min(m, i, n) + 1, x))
    or_fun = PsiLocal(lambda *x: tf.math.reduce_min(tf.concat(x, axis=1), axis=1, keepdims=True))
    all_nodes_expr = 'fix X = i in (((X;|p3>or) || (X;<p3|or));or)'

    def __init__(self, model: MGModel):
        """Initializes the instance with the model to explain.

        Args:
            model: The model to explain.
        """
        super().__init__()
        self.model = model
        if model.config is None:
            raise ValueError("Explained model must have a valid config!")
        self.query_node: int | None = None
        self.context = Context()
        self.compiler = MGCompiler(psi_functions={'node': MGExplainer.localize_node, 'or': MGExplainer.or_fun},
                                   sigma_functions={'or': MGExplainer.or_agg},
                                   phi_functions={'p3': MGExplainer.proj1},
                                   config=model.config)

    @staticmethod
    def _get_original_ids_func(explanation: tf.Tensor[bool]) -> Callable[[int], int]:
        """Returns a function that given an integer i returns the i-th node ID of the nodes in the explanation.

        The returned function is used so that the node IDs of the explanation sub-graph are the same as the original graph.

        Args:
            explanation: The boolean tensor of shape ``(n_nodes,)`` that marks with ``True`` the nodes that are part of the explanation
                and ``False`` those that do not.
        """
        sorted_node_ids = sorted(explanation_nodes(explanation))
        return lambda x: sorted_node_ids[x]

    def explain(self, query_node: int, inputs: tuple[tf.Tensor, ...], filename: str | None = None, open_browser: bool = True,
                engine: Literal["pyvis", "cosmo"] = 'pyvis') -> Graph:
        """Explain the label of a query node by generating the sub-graph of nodes that affected its value.

        Using the pyvis engine, the explanation is saved in a html file in the working directory. Using the cosmograph engine, the explanation is saved as a
        directory, containing an index.html file, in the working directory.

        Args:
            query_node: The node for which to generate the explanation.
            inputs: The inputs for the model to explain. This is the graph to which the query node belongs.
            filename: The name of the .html file to save in the working directory. The string ``graph_`` will be prepended to it.
            open_browser: If true, opens the default web browser and loads up the generated .html page.
            engine: The visualization engine to use. Options are ``pyvis`` for PyVis or ``cosmo`` for Cosmograph.

        Returns:
            The generated sub-graph.
        """
        if self.model.expr is None:
            raise ValueError("Explained model must have a valid expr!")
        # Build the model
        self.query_node = query_node
        self.context.clear()
        actual_outputs = self.model.call(inputs)
        try:
            right_branch = self.visit(deepcopy(self.model.expr))
        except VisitError:
            right_branch = mg_parser.parse(MGExplainer.all_nodes_expr)
        left_branch = mg_parser.parse('node[' + str(self.query_node) + ']')
        explainer_expr_tree = mg_parser.parse('left ; right')
        explainer_expr_tree.children = [left_branch, right_branch]
        explainer_model = self.compiler.compile(explainer_expr_tree)

        # Run the model
        hierarchy = tf.squeeze(explainer_model.call(inputs))
        explanation = tf.math.less(hierarchy, MGExplainer.INF)
        graph = make_graph(explanation, hierarchy, inputs, actual_outputs)
        print_graph(graph, id_generator=self._get_original_ids_func(explanation), hierarchical=True,
                    show_labels=True, filename=filename, open_browser=open_browser, engine=engine)
        return graph

    def atom_op(self, tree: Tree) -> Tree:
        name = str(tree.children[0].children[0])
        assert self.model.psi_functions is not None
        f = self.model.psi_functions.get(name)
        if re.search(r'^(p\d+|p\d+-|p-\d+|p\d+-\d+)$', name) is not None or isinstance(f, PsiLocal):  # is a projection
            new_op = mg_parser.parse('i')
        elif f is None:  # is a variable for an operator
            new_op = tree
        else:  # not local neither a variable
            raise VisitError('atom_op', tree, 'Nonlocal psi function')
        return new_op

    def id(self, tree):
        new_op = mg_parser.parse('i')
        return new_op

    def lhd(self, _: Tree) -> Tree:
        new_op = mg_parser.parse('|p3>or')
        return new_op

    def rhd(self, _: Tree) -> Tree:
        new_op = mg_parser.parse('<p3|or')
        return new_op

    def sequential_composition(self, tree: Tree) -> Tree:
        left, right = tree.children
        phi = self.visit(left)
        self.context.push(left)
        psi = self.visit(right)
        self.context.pop()

        tree.children = [phi, psi]
        return tree

    def parallel_composition(self, tree: Tree) -> Tree:
        children = self.visit_children(tree)
        new_op = mg_parser.parse('SUBST;or')
        tree_copy = tree.copy()
        tree_copy.children = children
        new_op.children[0] = tree_copy
        return new_op

    def ite(self, tree: Tree) -> Tree:
        raise VisitError('ite', tree, 'If-Then-Else expression')

    def star(self, tree: Tree) -> Tree:
        assert self.model.mg_layers is not None
        iters = self.model.mg_layers[hash(self.context.get(tree))].iters.numpy() - 1
        print(iters)
        new_op = tree.copy()
        new_op.children = self.visit_children(tree) + [Token('NUMBER', iters)]
        new_op.data = 'rep'
        return new_op

    def __default__(self, tree: Tree) -> Tree:  # local var expr, fun def, fun call, repeat
        tree.children = self.visit_children(tree)
        return tree
